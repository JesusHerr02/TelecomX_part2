# TelecomX: an√°lisis de evaluaci√≥n parte 2.
---

### Predicci√≥n de Churn (Cancelaci√≥n de Clientes)

---

## Prop√≥sito del an√°lisis
El objetivo central de este proyecto es **predecir la probabilidad de que un cliente cancele sus servicios de telecomunicaciones (churn)**.  
Con este modelo la empresa podr√°:
- Identificar segmentos de alto riesgo y actuar **antes** de que el cliente abandone.  
- Optimizar campa√±as de retenci√≥n y aumentar el **Lifetime Value (LTV)**.  
- Reducir costos de adquisici√≥n al disminuir la rotaci√≥n.

---


---

## üîß Proceso de preparaci√≥n de datos

### 1Ô∏è‚É£ Columnas y tipos
| **Variable**        | **Tipo**   | **Descripci√≥n** (ejemplo) |
|---------------------|------------|---------------------------|
| `customerID`        | ID         | Identificador √∫nico |
| `Churn`             | Binaria    | 0 = No cancel√≥, 1 = Cancel√≥ |
| `gender`            | Categ√≥rica | Male / Female |
| `SeniorCitizen`     | Num√©rica   | 0 o 1 |
| `Partner`, `Dependents`, `PhoneService`, etc. | Categ√≥ricas | S√≠/No |
| `Charges_Monthly`   | Num√©rica   | Cargo mensual en USD |
| `Cuentas_Diarias`   | Num√©rica   | Cargo promedio diario |

### 2Ô∏è‚É£ Codificaci√≥n / normalizaci√≥n
- **Categ√≥ricas binarias**: S√≠/No ‚Üí 1/0  
- **Categ√≥ricas ordinales**:  
  - *Contract*: `Month-to-month=0`, `One year=1`, `Two year=2`  
  - *PaymentMethod*: `Mailed check=0`, `Electronic=1`, `Credit card=2`, `Bank transfer=3`  
- **Num√©ricas**: se mantienen en escala original (no se escalaron porque LightGBM es insensible a la escala).

### 3Ô∏è‚É£ Divisi√≥n de datos
```python
X = df_final.drop(columns=['customerID', 'Churn'])
y = df_final['Churn']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
```
---
## Resultados
---

Evaluaci√≥n de los modelos


---

Los modelos fueron entrenados en dos ciclos. El primero de la manera tradicional, mediante la arquitectura train_test_split (30 - 70%); el segundo, a trav√©s de la validaci√≥n cruzada con 5 K-folds. El objetivo de esto era visualizar una mejor√≠a en la predicci√≥n. Ante esto, se procede con la siguiente tabla de inferencia:

| Modelo                 | Acc. Split | Acc. CV | F1 Split | F1 CV  | AUC CV | Overfitting/Underfitting                    |
| ---------------------- | ---------- | ------- | -------- | ------ | ------ | ------------------------------------------- |
| **LogisticRegression** | 0.7643     | 0.7711  | 0.7745   | 0.7799 | 0.8520 | Underfitting (bajo desempe√±o global)        |
| **SVM**                | 0.8161     | 0.8208  | 0.8177   | 0.8115 | 0.9168 | Bien generalizado                           |
| **Decision Tree**      | 0.8119     | 0.8004  | 0.8133   | 0.7825 | 0.8008 | Ligeramente sobreajustado                   |
| **Random Forest**      | 0.8451     | 0.8355  | 0.8417   | 0.8041 | 0.9287 | Ligeramente sobreajustado                   |
| **Gradient Boosting**  | 0.8573     | 0.8438  | 0.8582   | 0.8238 | 0.9388 | Muy buen desempe√±o, generaliza bien         |
| **KNN**                | 0.7775     | 0.7892  | 0.7818   | 0.7883 | 0.8746 | Ligeramente simple (baja AUC)               |
| **XGBoost**            | 0.8499     | 0.8344  | 0.8481   | 0.8062 | 0.9328 | Ligeramente sobreajustado                   |
| **LightGBM**           | 0.8576     | 0.8385  | 0.8566   | 0.8093 | 0.9379 | Mejor modelo global (consistente y robusto) |



---

**¬øCu√°l fue el mejor modelo entonces?**

LightGBM y Gradient Boosting son los modelos con mejor desempe√±o general:

- Altos valores de precisi√≥n, recall y F1 en ambas estrategias.

- Consistencia entre el train_test_split y la validaci√≥n cruzada, lo cual indica que generalizan bien.

- LightGBM tiene los mejores valores de AUC y precisi√≥n promedio, lo que lo hace especialmente adecuado para minimizar falsos positivos y maximizar la capacidad predictiva.

---

Bajo este panorama se propone lo siguiente:

| Modelo             | ¬øVale la pena seguirlo? | Motivo principal                                                          |
| ------------------ | ----------------------- | ------------------------------------------------------------------------- |
| LogisticRegression | No prioritario        | Modelo base √∫til, pero con menor desempe√±o.                               |
| SVM                | S√≠                    | Buen balance entre precisi√≥n y recall, sin se√±ales claras de overfitting. |
| Decision Tree      | Mejorable            | Simples, pero puede sobreajustarse f√°cilmente.                            |
| Random Forest      | S√≠                    | Robusto, pero ajustar hiperpar√°metros para evitar overfitting.            |
| Gradient Boosting  | Muy recomendable      | Alto desempe√±o y buena generalizaci√≥n.                                    |
| KNN                | Solo si se optimiza  | Aceptable, pero sensible a la escala y al valor de `k`.                   |
| XGBoost            | S√≠, pero con tuning   | Potente, aunque puede sobreajustarse sin regularizaci√≥n.                  |
| LightGBM           | **El mejor**         | Mejor equilibrio general. Altas m√©tricas y buena generalizaci√≥n.          |



---



---
Interpretaci√≥n del 2do mejor modelo (XGBoost)
---

| **Variable**                | **Impacto** | **Interpretaci√≥n**                                                |
| --------------------------- | ----------- | ----------------------------------------------------------------- |
| **Tenure (meses)**          | 15.2%       | Clientes con < 12 meses tienen 3.2x m√°s probabilidad de cancelar. |
| **Contract (tipo)**         | 12.8%       | Contratos *month-to-month* representan 78% de cancelaciones.      |
| **Charges\_Monthly**        | 11.4%       | Clientes con cargos > \$90/mes tienen 2.1x m√°s riesgo.            |
| **PaymentMethod**           | 9.7%        | *Electronic check* (vs. autom√°tico) aumenta 1.8x la cancelaci√≥n.  |
| **InternetService (Fiber)** | 8.9%        | Fibra √≥ptica tiene 1.5x m√°s cancelaciones vs. DSL.                |



---


---


Estrategias de Retenci√≥n Recomendadas


---


1. Reducir Cancelaci√≥n Temprana (<12 meses)
  - Acci√≥n: Ofrecer descuentos progresivos para clientes nuevos (ej. 20% descuento en mes 3-6).

  - Canal: Email/SMS automatizado al detectar inactividad.

2. Migrar a Contratos Anuales
  - Acci√≥n: Incentivar contratos de 1-2 a√±os con bonos de fidelidad.
  - Impacto Esperado: Reducci√≥n en churn.

3. Optimizar M√©todos de Pago
  - Acci√≥n:
  Migrar clientes de electronic check a automatizaci√≥n bancaria.
  - Ofrecer descuento 5% por pago autom√°tico.
  Impacto Esperado: Disminuir churn en 1.8x.

4. Personalizar Servicios Premium
  - Acci√≥n:
  Segmentar clientes con streaming y ofrecer paquetes flexibles (ej. "TV + Internet" con 15% descuento).
  - Alertas de uso excesivo para evitar "bill shock".

5. Programa de Lealtad Senior
  - Acci√≥n:
  Tarifas preferenciales para mayores de 65 a√±os (ya tienen baja cancelaci√≥n).
  - Soporte t√©cnico prioritario.
